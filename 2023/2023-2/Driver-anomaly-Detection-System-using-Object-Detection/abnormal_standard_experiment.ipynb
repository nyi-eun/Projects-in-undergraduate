{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ultralytics\n",
    "#!pip install numpy==1.23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from sklearn.metrics import accuracy_score, recall_score \n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시퀀스 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path1 = './monitoring/images_sleep'\n",
    "folder_path2 = './monitoring/images_phone'\n",
    "folder_path3 = './monitoring/images_normal'\n",
    "\n",
    "image_paths1 = sorted([os.path.join(folder_path1, f) for f in os.listdir(folder_path1) if f.startswith('SGA') and f.endswith('.jpg')])\n",
    "image_paths2 = sorted([os.path.join(folder_path2, f) for f in os.listdir(folder_path2) if f.startswith('SGA') and f.endswith('.jpg')])\n",
    "image_paths3 = sorted([os.path.join(folder_path3, f) for f in os.listdir(folder_path3) if f.startswith('SGA') and f.endswith('.jpg')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 이미지 경로들을 기반으로 비디오 시퀀스 리스트를 생성\n",
    "def making_video_list(videos, image_paths):\n",
    "    current_video_sequences = []\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        video_id = image_path.split('IMG')[0]\n",
    "\n",
    "        # 현재 비디오 시퀀스와 비디오 ID가 동일한 경우 현재 시퀀스에 이미지 경로 추가\n",
    "        if current_video_sequences and video_id == current_video_sequences[0].split('IMG')[0]:\n",
    "            current_video_sequences.append(image_path)\n",
    "        else:\n",
    "            \n",
    "            # 현재 비디오 시퀀스가 존재하면 이전 시퀀스를 비디오 리스트에 추가\n",
    "            if current_video_sequences:\n",
    "                videos.append(current_video_sequences)\n",
    "            current_video_sequences = [image_path]\n",
    "\n",
    "    # 마지막 비디오 시퀀스가 존재하면 비디오 리스트에 추가\n",
    "    if current_video_sequences:\n",
    "        videos.append(current_video_sequences)\n",
    "    \n",
    "    return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_sleep = making_video_list(videos, image_paths1)\n",
    "videos_phone = making_video_list(videos, image_paths2)\n",
    "videos_all = making_video_list(videos, image_paths3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#주어진 비디오 시퀀스에 대해 특정 키워드가 있는지 탐색하는 함수 제작\n",
    "\n",
    "def making_answer_list(videos):\n",
    "    answer = []\n",
    "    keywords = ['sleep', 'phone']\n",
    "\n",
    "    for video in videos:\n",
    "        found = False\n",
    "        for image_path in video:\n",
    "            for keyword in keywords:\n",
    "                #이미지 경로에 키워드가 포함되어 있으면 발견으로 표시하고 종료\n",
    "                if keyword in image_path:\n",
    "                    found = True\n",
    "                    break\n",
    "            if found:\n",
    "                break\n",
    "\n",
    "        if found:\n",
    "            answer.append(1)\n",
    "        else:\n",
    "            answer.append(0)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = making_answer_list(videos) # 영상 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(data, target):\n",
    "    res = []\n",
    "    lis = data\n",
    "    while True:\n",
    "        try:\n",
    "            res.append(lis.index(target) + (res[-1]+1 if len(res)!=0 else 0))\n",
    "            lis = data[res[-1]+1:]\n",
    "        except:\n",
    "            break     \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_index = find_index(result,1)\n",
    "normal_index = find_index(result,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_index = abnormal_index[:1000]\n",
    "use_index = use_index + abnormal_index[-1000:]\n",
    "use_index = use_index + normal_index[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "videos = [videos[index] for index in use_index]\n",
    "result = [result[index] for index in use_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이상행동 탐지 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [0 for i in range(len(videos))] # 예측 결과 저장\n",
    "phone_pred = [0 for i in range(len(videos))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(model1.names) # {0: 'Leye', 1: 'Reye', 2: 'Phone'}\n",
    "# print(model2.names) # {0: 'body', 1: 'face'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = YOLO('/home/work/VisionAI/subeen/runs/detect/train17/weights/best.pt')\n",
    "model2 = YOLO('/home/work/VisionAI/monitoring/runs/detect/train13(epoch10)/weights/best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phone_ratio_model1 = [0 for i in range(len(videos))] \n",
    "sleep_ratio_model1 = [0 for i in range(len(videos))] \n",
    "sleep_ratio_model2_body = [0 for i in range(len(videos))] \n",
    "sleep_ratio_model2_face = [0 for i in range(len(videos))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(videos)) :\n",
    "    \n",
    "    seq_lst = videos[i]\n",
    "    \n",
    "    phone_model1 = []  # 모델 1에서 탐지된 핸드폰의 확률 리스트 초기화\n",
    "    sleep_model1 = []  # 모델 1에서 감은 눈의 확률 리스트 초기화\n",
    "    sleep_model2_body = []  # 모델 2에서 감은 눈 (Body)의 BoundingBox 리스트 초기화\n",
    "    sleep_model2_face = []  # 모델 2에서 감은 눈 (Face)의 BoundingBox 리스트 초기화\n",
    "\n",
    "    # 각 비디오 시퀀스에 대한 졸음 예측 수행\n",
    "    for seq_img in seq_lst : \n",
    "\n",
    "        # model 1 실행 코드 (epoch 10 기준)\n",
    "        model1 = YOLO('/home/work/VisionAI/subeen/runs/detect/train17/weights/best.pt')\n",
    "        model1_result = model1.predict(source = seq_img)\n",
    "\n",
    "        model1_pred_class = model1_result[0].boxes.cls.cpu().detach().numpy()\n",
    "        model1_pred_probs = model1_result[0].boxes.conf.cpu().detach().numpy()\n",
    "        model1_dict = dict(zip(model1_pred_class, model1_pred_probs))\n",
    "\n",
    "        # 핸드폰 탐지한 경우\n",
    "        if 2 in model1_dict.keys() :\n",
    "            phone_pred[i] = phone_model1.append(model1_dict[2])\n",
    "            del model1_dict[2]\n",
    "        \n",
    "        # 감은 눈에 대한 확률\n",
    "        if 2 == len(list(model1_dict.values())):\n",
    "            sleep_model1.append(model1_dict[0] * model1_dict[1])\n",
    "        elif 1 == len(list(model1_dict.values())):\n",
    "            sleep_model1.append(list(model1_dict.values())[0]/2)\n",
    "        else :\n",
    "            sleep_model1.append(0)\n",
    "\n",
    "        # model 2 실행 코드 (epoch 10 기준)\n",
    "        model2 = YOLO('/home/work/VisionAI/monitoring/runs/detect/train13(epoch10)/weights/best.pt')\n",
    "        model2_result = model2.predict(source = seq_img)\n",
    "\n",
    "        model2_pred_class = model2_result[0].boxes.cls.cpu().detach().numpy()\n",
    "        model2_pred_bbox = model2_result[0].boxes.xywh.cpu().detach().numpy()\n",
    "        model2_dict = dict(zip(model2_pred_class, model2_pred_bbox))\n",
    "        \n",
    "        # 모델 2에서 감은 눈 (Body)와 감은 눈 (Face)의 BoundingBox 정보 저장\n",
    "        sleep_model2_body.append(model2_dict[0])\n",
    "        sleep_model2_face.append(model2_dict[1])\n",
    "    \n",
    "    # 결과 리스트에 각 모델의 결과 저장\n",
    "    phone_ratio_model1[i] = phone_model1\n",
    "    sleep_ratio_model1[i] = sleep_model1\n",
    "    sleep_ratio_model2_body[i] = sleep_model2_body\n",
    "    sleep_ratio_model2_face[i] = sleep_model2_face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(phone_ratio_model1), len(sleep_ratio_model1), len(sleep_ratio_model2_body), len(sleep_ratio_model2_face)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d72d40",
   "metadata": {},
   "source": [
    "#### 오차 행렬 출력 및 plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "#     plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "#     print(cm)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold 설정\n",
    "phone_threshold = 0.85\n",
    "body_face_standard = 0.2\n",
    "sleep_ratio_threshold = 0.15\n",
    "sleep_threshold = 0.15\n",
    "\n",
    "sleep_pred = [0 for i in range(len(videos))] # 예측 결과 저장\n",
    "\n",
    "for i in range(len(videos)) :\n",
    "    \n",
    "    seq_lst = videos[i]\n",
    "    sleep_ratio_lst = []\n",
    "\n",
    "    for j in range(len(seq_lst)) :\n",
    "        \n",
    "        sleep_ratio = 0 # 해당 이미지의 졸음지수 초기화\n",
    "        \n",
    "        try :\n",
    "            sleep_ratio = sleep_ratio_model1[i][j]\n",
    "            # Body BoundingBox의 중간 지점에 해당하는 Y 좌표 계산\n",
    "            body_guidpoint_y = sleep_ratio_model2_body[i][j][1] + (body_face_standard * sleep_ratio_model2_body[i][j][3])\n",
    "            # Face BoundingBox의 비율 계산\n",
    "            face_bbox_ratio =  (sleep_ratio_model2_face[i][j][1] + sleep_ratio_model2_face[i][j][3] - body_guidpoint_y) / sleep_ratio_model2_face[i][j][3]\n",
    "            # 졸음 지수를 모델 1과 Face BoundingBox 비율의 평균으로 업데이트\n",
    "            sleep_ratio = (sleep_ratio_model1[i][j] + face_bbox_ratio) / 2\n",
    "            \n",
    "        except :\n",
    "        \n",
    "            try :\n",
    "                # Body BoundingBox의 중간 지점에 해당하는 Y 좌표 계산\n",
    "                body_guidpoint_y = sleep_ratio_model2_body[i][j][1] + (body_face_standard * sleep_ratio_model2_body[i][j][3])\n",
    "                # Face BoundingBox의 비율 계산\n",
    "                face_bbox_ratio =  (sleep_ratio_model2_face[i][j][1] + sleep_ratio_model2_face[i][j][3] - body_guidpoint_y) / sleep_ratio_model2_face[i][j][3]\n",
    "                # 졸음 지수를 Face BoundingBox 비율로 업데이트\n",
    "                sleep_ratio = face_bbox_ratio\n",
    "                # 졸음 비율이 기준보다 높으면 리스트에 1 추가\n",
    "                if sleep_ratio >= sleep_ratio_threshold :\n",
    "                    sleep_ratio_lst.append(1)\n",
    "                \n",
    "                continue\n",
    "                \n",
    "            except :\n",
    "                continue\n",
    "        \n",
    "        # 졸음 비율이 기준보다 높으면 리스트에 1 추가\n",
    "        if sleep_ratio >= sleep_ratio_threshold :\n",
    "            sleep_ratio_lst.append(1)\n",
    "\n",
    "    #졸음 비율이 기준보다 높은 경우 1로 설정\n",
    "    if ((sum(sleep_ratio_lst) / len(seq_lst)) >= sleep_threshold) :\n",
    "        sleep_pred[i] = 1\n",
    "\n",
    "\n",
    "# 핸드폰 예측 결과 업데이트\n",
    "final_pred = sleep_pred.copy()\n",
    "for i in range(len(phone_ratio_model1)) :\n",
    "    if len(phone_ratio_model1[i]) > 0 :\n",
    "        if max(phone_ratio_model1[i]) >= phone_threshold :\n",
    "            final_pred[i] = 1\n",
    "\n",
    "# Confusion Matrix 계산\n",
    "cnf_matrix = confusion_matrix(result, final_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "print('phone_threshold :', phone_threshold)\n",
    "print('body_face_standard :', body_face_standard)\n",
    "print('sleep_ratio_threshold :', sleep_ratio_threshold)\n",
    "print('sleep_threshold :', sleep_threshold)\n",
    "print('Accaracy :', accuracy_score(result, final_pred))\n",
    "print('Recall :', recall_score(result, final_pred))\n",
    "print('-----')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=['0', '1'], normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 1.9.0 on Python 3.8 (CUDA 11.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
