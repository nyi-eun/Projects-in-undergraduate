{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPgSMYZ2bw9Bxq8z+BEh0eW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Drive 연결"],"metadata":{"id":"kEMMvwpHSEm-"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"osevzJeLSKQo","executionInfo":{"status":"ok","timestamp":1701263265812,"user_tz":-540,"elapsed":18443,"user":{"displayName":"유광열","userId":"08477822120021600377"}},"outputId":"a4b9fa64-2b04-40df-f394-e130bf30a904"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["#%cd /content/drive/MyDrive/poster\n","\n","#!unzip -qq \"/content/drive/MyDrive/Poster Session.zip\""],"metadata":{"id":"r_Tx87PzSLvf","executionInfo":{"status":"ok","timestamp":1701263265812,"user_tz":-540,"elapsed":3,"user":{"displayName":"유광열","userId":"08477822120021600377"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Install"],"metadata":{"id":"h0DLq94_ScuV"}},{"cell_type":"code","source":["#@title 3D_DreamGaussian\n","%cd /content/drive/MyDrive/conference/dreamgaussian\n","\n","# install dependencies\n","!pip install -q einops plyfile dearpygui huggingface_hub diffusers==0.21.4 accelerate transformers xatlas trimesh PyMCubes pymeshlab rembg[gpu,cli] omegaconf ninja\n","\n","# build extension from source (can be slow)\n","# !git clone --recursive https://github.com/ashawkey/diff-gaussian-rasterization\n","# !pip install -q ./diff-gaussian-rasterization\n","# !pip install -q ./simple-knn\n","\n","# pre-built wheels (faster)\n","!pip install -q https://github.com/camenduru/diff-gaussian-rasterization/releases/download/v1.0/diff_gaussian_rasterization-0.0.0-cp310-cp310-linux_x86_64.1.whl\n","!pip install -q https://github.com/camenduru/diff-gaussian-rasterization/releases/download/v1.0/simple_knn-0.0.0-cp310-cp310-linux_x86_64.1.whl\n","\n","# nvdiffrast\n","!pip install -q git+https://github.com/NVlabs/nvdiffrast\n","\n","# kiuikit\n","!pip install -q git+https://github.com/ashawkey/kiuikit"],"metadata":{"id":"2sOl-0n9SLs9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701263346325,"user_tz":-540,"elapsed":80515,"user":{"displayName":"유광열","userId":"08477822120021600377"}},"outputId":"eac6542d-eb81-4e83-f7c9-0e3bc5ff17a9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/conference/dreamgaussian\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.4/229.4 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m688.5/688.5 kB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.3/274.3 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m115.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.9/52.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.9/92.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.1/157.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.7/302.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","lida 0.0.10 requires kaleido, which is not installed.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\n","tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for nvdiffrast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for kiui (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["# gradio\n","!pip install gradio_client"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5FfTekBOXlkt","executionInfo":{"status":"ok","timestamp":1701263353760,"user_tz":-540,"elapsed":7439,"user":{"displayName":"유광열","userId":"08477822120021600377"}},"outputId":"40ad4e07-701f-4e76-87a8-4c5f37490599"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gradio_client in /usr/local/lib/python3.10/dist-packages (0.7.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio_client) (2023.6.0)\n","Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio_client) (0.25.2)\n","Requirement already satisfied: huggingface-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from gradio_client) (0.19.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio_client) (23.2)\n","Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio_client) (2.31.0)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio_client) (4.8.0)\n","Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio_client) (11.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio_client) (3.13.1)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio_client) (4.66.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13.0->gradio_client) (6.0.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio_client) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio_client) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio_client) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio_client) (2023.7.22)\n","Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio_client) (3.7.1)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio_client) (1.0.2)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio_client) (1.3.0)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->gradio_client) (0.14.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio_client) (1.1.3)\n"]}]},{"cell_type":"markdown","source":["# Run"],"metadata":{"id":"GZOPOLyyS_5s"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/conference"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fXBuWX5OTD6N","executionInfo":{"status":"ok","timestamp":1701263353760,"user_tz":-540,"elapsed":7,"user":{"displayName":"유광열","userId":"08477822120021600377"}},"outputId":"558fe6f0-4667-4a59-fdd4-d12cf996546f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/conference\n"]}]},{"cell_type":"code","source":["!python Front_base.py"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ud-mfKEoSLnm","executionInfo":{"status":"ok","timestamp":1701264093482,"user_tz":-540,"elapsed":734961,"user":{"displayName":"유광열","userId":"08477822120021600377"}},"outputId":"6f108fd8-8eb5-4adc-f26e-ae78c9574580"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["style 바꿀 신발 선택하세요(cro,newbal,nike,adidas,mlb 중 택1): nike\n","style 바꿀 mask 부분 선택하세요(base,lace,line,nike,sole): sole\n","원하는 스타일을 선택하세요(aurora,galaxy_1,2,3,4,5,6): aurora\n","\n"," == Building Reversible Residual Network 91 Blocks== \n","Save at output/nike_aurora.png\n","Style transfer success\n","Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx' to file '/root/.u2net/u2net.onnx'.\n","100%|████████████████████████████████████████| 176M/176M [00:00<00:00, 746GB/s]\n","[INFO] loading image results/output_mask_nike_aurora.png...\n","[INFO] background removal...\n","[INFO] recenter...\n","\u001b[0m3D Preprocessing success\n","Loaded as API: https://one-2-3-45-one-2-3-45.hf.space/ ✔\n","3D mulriview success\n","[INFO] load image from results/output_mask_nike_aurora_rgba.png...\n","Number of points at initialisation :  10000\n","[INFO] loading zero123...\n","2023-11-29 13:11:21.574397: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-29 13:11:21.574472: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-29 13:11:21.574535: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-29 13:11:22.674409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","model_index.json: 100% 562/562 [00:00<00:00, 3.47MB/s]\n","Fetching 11 files:   0% 0/11 [00:00<?, ?it/s]\n","(…)ature_extractor/preprocessor_config.json: 100% 518/518 [00:00<00:00, 2.21MB/s]\n","\n","unet/config.json: 100% 1.68k/1.68k [00:00<00:00, 8.90MB/s]\n","\n","image_encoder/config.json: 100% 585/585 [00:00<00:00, 3.70MB/s]\n","\n","scheduler/scheduler_config.json: 100% 502/502 [00:00<00:00, 3.32MB/s]\n","\n","vae/config.json: 100% 577/577 [00:00<00:00, 3.78MB/s]\n","\n","clip_camera_projection/config.json: 100% 132/132 [00:00<00:00, 744kB/s]\n","Fetching 11 files:   9% 1/11 [00:00<00:09,  1.03it/s]\n","model.fp16_ema.safetensors:   0% 0.00/608M [00:00<?, ?B/s]\u001b[A\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:   0% 0.00/1.19M [00:00<?, ?B/s]\u001b[A\u001b[A\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:   0% 0.00/167M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:   2% 10.5M/608M [00:00<00:13, 44.4MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:   0% 0.00/1.72G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors: 100% 1.19M/1.19M [00:00<00:00, 7.72MB/s]\n","Fetching 11 files:  18% 2/11 [00:01<00:06,  1.42it/s]\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:   6% 10.5M/167M [00:00<00:03, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:   5% 31.5M/608M [00:00<00:08, 69.2MB/s]\u001b[A\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  19% 31.5M/167M [00:00<00:02, 62.9MB/s]\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:   9% 52.4M/608M [00:00<00:10, 53.7MB/s]\u001b[A\n","model.fp16_ema.safetensors:  10% 62.9M/608M [00:01<00:09, 59.0MB/s]\u001b[A\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  31% 52.4M/167M [00:00<00:02, 55.5MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  38% 62.9M/167M [00:01<00:01, 62.9MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:   1% 10.5M/1.72G [00:01<03:03, 9.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  14% 83.9M/608M [00:01<00:09, 53.5MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:   1% 21.0M/1.72G [00:01<01:46, 16.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  50% 83.9M/167M [00:01<00:01, 46.1MB/s]\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:   2% 31.5M/1.72G [00:01<01:12, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  17% 105M/608M [00:01<00:09, 53.1MB/s] \u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:   2% 41.9M/1.72G [00:01<00:52, 31.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  21% 126M/608M [00:02<00:07, 66.3MB/s]\u001b[A\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  63% 105M/167M [00:01<00:01, 53.8MB/s] \u001b[A\u001b[A\u001b[A\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  69% 115M/167M [00:02<00:00, 56.3MB/s]\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  22% 136M/608M [00:02<00:09, 48.7MB/s]\u001b[A\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  81% 136M/167M [00:02<00:00, 50.1MB/s]\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  26% 157M/608M [00:02<00:08, 53.9MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:   3% 52.4M/1.72G [00:02<01:24, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  28% 168M/608M [00:02<00:07, 57.7MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:   4% 73.4M/1.72G [00:02<00:48, 34.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  94% 157M/167M [00:02<00:00, 52.3MB/s]\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  31% 189M/608M [00:03<00:07, 56.1MB/s]\u001b[A\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors: 100% 167M/167M [00:03<00:00, 47.3MB/s]\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  33% 199M/608M [00:03<00:06, 60.8MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors: 100% 167M/167M [00:04<00:00, 36.4MB/s]\n","\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:   5% 94.4M/1.72G [00:04<01:23, 19.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  34% 210M/608M [00:04<00:17, 23.2MB/s]\u001b[A\n","model.fp16_ema.safetensors:  38% 231M/608M [00:05<00:11, 34.3MB/s]\u001b[A\n","model.fp16_ema.safetensors:  41% 252M/608M [00:05<00:07, 46.9MB/s]\u001b[A\n","model.fp16_ema.safetensors:  45% 273M/608M [00:05<00:05, 59.9MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:   6% 105M/1.72G [00:05<01:21, 19.8MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  47% 283M/608M [00:05<00:05, 63.8MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:   7% 115M/1.72G [00:05<01:02, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  48% 294M/608M [00:05<00:05, 53.4MB/s]\u001b[A\n","model.fp16_ema.safetensors:  50% 304M/608M [00:05<00:05, 60.5MB/s]\u001b[A\n","model.fp16_ema.safetensors:  52% 315M/608M [00:06<00:04, 59.5MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:   8% 136M/1.72G [00:05<00:57, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  53% 325M/608M [00:06<00:04, 62.6MB/s]\u001b[A\n","model.fp16_ema.safetensors:  57% 346M/608M [00:06<00:05, 52.2MB/s]\u001b[A\n","model.fp16_ema.safetensors:  59% 357M/608M [00:06<00:04, 56.4MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:   9% 157M/1.72G [00:06<00:56, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  60% 367M/608M [00:07<00:04, 52.5MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  10% 178M/1.72G [00:06<00:40, 38.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  64% 388M/608M [00:07<00:03, 68.9MB/s]\u001b[A\n","model.fp16_ema.safetensors:  66% 398M/608M [00:07<00:03, 66.5MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  11% 189M/1.72G [00:07<00:45, 33.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  69% 419M/608M [00:07<00:02, 64.6MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  12% 199M/1.72G [00:07<00:43, 35.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  71% 430M/608M [00:07<00:02, 66.8MB/s]\u001b[A\n","model.fp16_ema.safetensors:  74% 451M/608M [00:08<00:02, 69.3MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  12% 210M/1.72G [00:08<00:53, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  13% 220M/1.72G [00:08<00:45, 33.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  78% 472M/608M [00:08<00:02, 61.7MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  14% 241M/1.72G [00:08<00:41, 35.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  81% 493M/608M [00:09<00:03, 35.4MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  15% 252M/1.72G [00:09<00:54, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  83% 503M/608M [00:09<00:02, 39.1MB/s]\u001b[A\n","model.fp16_ema.safetensors:  85% 514M/608M [00:09<00:02, 45.2MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  16% 273M/1.72G [00:09<00:38, 38.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  86% 524M/608M [00:10<00:01, 51.9MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  16% 283M/1.72G [00:09<00:32, 43.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  88% 535M/608M [00:10<00:01, 58.7MB/s]\u001b[A\n","model.fp16_ema.safetensors:  90% 545M/608M [00:10<00:00, 66.2MB/s]\u001b[A\n","model.fp16_ema.safetensors:  91% 556M/608M [00:10<00:00, 72.6MB/s]\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  17% 294M/1.72G [00:10<00:36, 39.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  18% 304M/1.72G [00:10<00:30, 46.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","model.fp16_ema.safetensors:  95% 577M/608M [00:10<00:00, 72.9MB/s]\u001b[A\n","model.fp16_ema.safetensors:  98% 598M/608M [00:10<00:00, 85.8MB/s]\u001b[A\n","model.fp16_ema.safetensors: 100% 608M/608M [00:11<00:00, 55.1MB/s]\n","Fetching 11 files:  45% 5/11 [00:12<00:16,  2.78s/it]\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  18% 315M/1.72G [00:10<00:38, 36.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  19% 325M/1.72G [00:10<00:31, 43.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  20% 336M/1.72G [00:11<00:28, 48.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  20% 346M/1.72G [00:11<00:40, 34.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  21% 367M/1.72G [00:12<00:47, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  22% 377M/1.72G [00:12<00:42, 31.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  23% 398M/1.72G [00:13<00:38, 34.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  24% 419M/1.72G [00:13<00:35, 37.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  25% 430M/1.72G [00:13<00:30, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  26% 451M/1.72G [00:14<00:34, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  27% 461M/1.72G [00:14<00:29, 41.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  27% 472M/1.72G [00:15<00:44, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  28% 482M/1.72G [00:15<00:44, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  29% 493M/1.72G [00:16<00:40, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  29% 503M/1.72G [00:17<00:57, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  30% 514M/1.72G [00:17<00:44, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  30% 524M/1.72G [00:17<00:42, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  32% 545M/1.72G [00:17<00:26, 43.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  32% 556M/1.72G [00:19<00:59, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  34% 577M/1.72G [00:20<01:15, 15.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  35% 598M/1.72G [00:21<00:49, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  35% 608M/1.72G [00:21<00:58, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  37% 629M/1.72G [00:22<00:50, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  37% 640M/1.72G [00:22<00:45, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  38% 661M/1.72G [00:23<00:39, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  40% 682M/1.72G [00:24<00:34, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  41% 703M/1.72G [00:24<00:26, 37.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  41% 713M/1.72G [00:25<00:36, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  43% 734M/1.72G [00:26<00:37, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  44% 755M/1.72G [00:26<00:26, 36.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  45% 765M/1.72G [00:26<00:30, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  46% 786M/1.72G [00:27<00:26, 34.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  46% 797M/1.72G [00:27<00:23, 39.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  48% 818M/1.72G [00:27<00:22, 39.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  48% 828M/1.72G [00:28<00:21, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  49% 839M/1.72G [00:28<00:31, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  49% 849M/1.72G [00:29<00:28, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  51% 870M/1.72G [00:29<00:26, 32.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  52% 891M/1.72G [00:30<00:26, 31.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  53% 912M/1.72G [00:30<00:19, 41.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  54% 923M/1.72G [00:31<00:24, 33.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  54% 933M/1.72G [00:31<00:21, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  55% 944M/1.72G [00:31<00:23, 32.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  56% 954M/1.72G [00:31<00:20, 36.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  56% 965M/1.72G [00:32<00:17, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  57% 975M/1.72G [00:32<00:24, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  57% 986M/1.72G [00:32<00:19, 37.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  58% 996M/1.72G [00:33<00:26, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  59% 1.01G/1.72G [00:33<00:20, 34.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  60% 1.03G/1.72G [00:34<00:20, 33.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  61% 1.05G/1.72G [00:34<00:17, 37.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  62% 1.06G/1.72G [00:35<00:19, 34.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  63% 1.08G/1.72G [00:35<00:18, 34.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  63% 1.09G/1.72G [00:35<00:16, 37.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  64% 1.10G/1.72G [00:36<00:25, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  65% 1.12G/1.72G [00:36<00:16, 35.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  66% 1.13G/1.72G [00:37<00:19, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  66% 1.14G/1.72G [00:37<00:19, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  67% 1.15G/1.72G [00:38<00:21, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  68% 1.16G/1.72G [00:38<00:22, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  68% 1.17G/1.72G [00:39<00:18, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  69% 1.18G/1.72G [00:39<00:23, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  70% 1.21G/1.72G [00:40<00:22, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  71% 1.23G/1.72G [00:41<00:15, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  72% 1.24G/1.72G [00:41<00:17, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  73% 1.25G/1.72G [00:42<00:18, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  73% 1.26G/1.72G [00:42<00:17, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  74% 1.27G/1.72G [00:42<00:16, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  74% 1.28G/1.72G [00:42<00:12, 33.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  75% 1.29G/1.72G [00:43<00:13, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  76% 1.30G/1.72G [00:43<00:12, 34.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  76% 1.31G/1.72G [00:44<00:14, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  77% 1.32G/1.72G [00:44<00:11, 34.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  77% 1.33G/1.72G [00:44<00:09, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  78% 1.34G/1.72G [00:44<00:13, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  79% 1.35G/1.72G [00:45<00:10, 36.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  79% 1.36G/1.72G [00:45<00:10, 34.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  80% 1.37G/1.72G [00:45<00:11, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  81% 1.38G/1.72G [00:46<00:10, 31.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  81% 1.39G/1.72G [00:46<00:11, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  82% 1.41G/1.72G [00:46<00:09, 33.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  82% 1.42G/1.72G [00:47<00:15, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  83% 1.43G/1.72G [00:48<00:13, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  84% 1.44G/1.72G [00:48<00:09, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  84% 1.45G/1.72G [00:49<00:14, 19.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  85% 1.46G/1.72G [00:49<00:10, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  85% 1.47G/1.72G [00:49<00:10, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  86% 1.48G/1.72G [00:50<00:08, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  87% 1.49G/1.72G [00:50<00:06, 37.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  87% 1.50G/1.72G [00:51<00:09, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  88% 1.51G/1.72G [00:51<00:07, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  88% 1.52G/1.72G [00:51<00:08, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  89% 1.53G/1.72G [00:52<00:08, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  90% 1.54G/1.72G [00:52<00:06, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  90% 1.55G/1.72G [00:53<00:07, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  91% 1.56G/1.72G [00:53<00:05, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  91% 1.57G/1.72G [00:53<00:05, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  92% 1.58G/1.72G [00:53<00:04, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  93% 1.59G/1.72G [00:54<00:03, 39.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  93% 1.60G/1.72G [00:54<00:03, 38.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  94% 1.61G/1.72G [00:54<00:02, 46.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  95% 1.63G/1.72G [00:55<00:03, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  95% 1.64G/1.72G [00:55<00:02, 36.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  96% 1.65G/1.72G [00:55<00:01, 45.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  96% 1.66G/1.72G [00:55<00:02, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  97% 1.67G/1.72G [00:56<00:01, 39.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  98% 1.68G/1.72G [00:56<00:01, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  98% 1.69G/1.72G [00:56<00:00, 34.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors:  99% 1.70G/1.72G [00:56<00:00, 42.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n","\n","\n","\n","(…)usion_pytorch_model.fp16_ema.safetensors: 100% 1.72G/1.72G [00:57<00:00, 29.9MB/s]\n","Fetching 11 files: 100% 11/11 [00:59<00:00,  5.37s/it]\n","Loading pipeline components...: 100% 6/6 [00:00<00:00,  8.63it/s]\n","[INFO] loaded zero123!\n","100% 1000/1000 [02:56<00:00,  5.68it/s]\n","[INFO] save model to logs/results/output_mask_nike_aurora_model.ply.\n","/usr/local/lib/python3.10/dist-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","\u001b[93mTensor occ\u001b[0m \u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m128\u001b[0m, \u001b[1;36m128\u001b[0m, \u001b[1;36m128\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m torch.float32 cu\u001b[1;92mda:0\u001b[0m ∈ \u001b[1m[\u001b[0m\u001b[1;36m0.0\u001b[0m, \u001b[1;36m86.92102813720703\u001b[0m\u001b[1m]\u001b[0m μ = \n","\u001b[1;36m0.4760240912437439\u001b[0m σ = \u001b[1;36m2.1251978874206543\u001b[0m\n","[INFO] mesh cleaning: (42632, 3) --> (35993, 3), (85292, 3) --> (72042, 3)\n","[INFO] marching cubes result: torch.Size([35993, 3]) (-0.8843256831169128-0.8984424471855164), torch.Size([72042, 3])\n","[INFO] unwrap uv...\n","[INFO] save model to logs/results/output_mask_nike_aurora_mesh.obj.\n","\u001b[0m3D reconstruction stage1 success\n","[load_obj] use texture from: logs/results/output_mask_nike_aurora_mesh_albedo.png\n","[load_obj] load texture: (1024, 1024, 3)\n","[Mesh loading] v: torch.Size([45152, 3]), f: torch.Size([72042, 3])\n","[Mesh loading] vn: torch.Size([45152, 3]), fn: torch.Size([72042, 3])\n","[INFO] load image from results/output_mask_nike_aurora_rgba.png...\n","[INFO] loading zero123...\n","2023-11-29 13:19:17.041296: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-29 13:19:17.041348: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-29 13:19:17.041385: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-29 13:19:18.646297: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Loading pipeline components...: 100% 6/6 [00:01<00:00,  3.99it/s]\n","[INFO] loaded zero123!\n","100% 200/200 [01:38<00:00,  2.03it/s]\n","[INFO] save model to logs/results/output_mask_nike_aurora.obj.\n","\u001b[0m3D reconstruction stage2 success\n","[load_obj] use texture from: logs/results/output_mask_nike_aurora_albedo.png\n","[load_obj] load texture: (1024, 1024, 3)\n","[Mesh loading] v: torch.Size([45152, 3]), f: torch.Size([72042, 3])\n","[Mesh loading] vn: torch.Size([45152, 3]), fn: torch.Size([72042, 3])\n","  0% 0/1 [00:00<?, ?it/s]\n","  0% 0/180 [00:00<?, ?it/s]\u001b[A\n","  1% 1/180 [00:00<02:27,  1.21it/s]\u001b[A\n","  7% 12/180 [00:00<00:09, 17.23it/s]\u001b[A\n"," 13% 24/180 [00:01<00:04, 34.49it/s]\u001b[A\n"," 21% 37/180 [00:01<00:02, 52.68it/s]\u001b[A\n"," 27% 49/180 [00:01<00:01, 66.60it/s]\u001b[A\n"," 34% 61/180 [00:01<00:01, 78.64it/s]\u001b[A\n"," 40% 72/180 [00:01<00:01, 84.59it/s]\u001b[A\n"," 48% 86/180 [00:01<00:00, 97.17it/s]\u001b[A\n"," 55% 99/180 [00:01<00:00, 105.10it/s]\u001b[A\n"," 62% 111/180 [00:01<00:00, 106.00it/s]\u001b[A\n"," 69% 124/180 [00:01<00:00, 112.30it/s]\u001b[A\n"," 77% 138/180 [00:01<00:00, 118.70it/s]\u001b[A\n"," 84% 151/180 [00:02<00:00, 111.30it/s]\u001b[A\n"," 91% 163/180 [00:02<00:00, 111.25it/s]\u001b[A\n","100% 180/180 [00:02<00:00, 75.94it/s] \n","100% 1/1 [00:02<00:00,  2.37s/it]\n","3D onj generation success\n","time : 719.2749342918396\n"]}]},{"cell_type":"markdown","source":["# Video"],"metadata":{"id":"FtTWOQZbZ_Vw"}},{"cell_type":"code","source":["from IPython.display import HTML\n","from base64 import b64encode\n","\n","def show_video(video_path, video_width=450):\n","  video_file = open(video_path, \"r+b\").read()\n","  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n","  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")\n","\n","show_video('/content/drive/MyDrive/conference/results/output_mask_nike_aurora.mp4')"],"metadata":{"id":"Op3Um-wsSLh0","colab":{"base_uri":"https://localhost:8080/","height":470,"output_embedded_package_id":"1l7PWZglvyHnrG3SrfP2ZeoZGUggJZ9dk"},"executionInfo":{"status":"ok","timestamp":1701264119850,"user_tz":-540,"elapsed":14,"user":{"displayName":"유광열","userId":"08477822120021600377"}},"outputId":"3c965edb-197c-4ef8-969c-ab7340f3932f"},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"-WLCEwQUSLeh"},"execution_count":null,"outputs":[]}]}