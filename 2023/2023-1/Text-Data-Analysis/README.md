<h2 align='center'> 주요 시사 별 Word Cloud를 통한 특징 키워드 추출 및 LDA를 통한 주제 분석 </h2>
<h3 align='center'> [전공] 텍스트데이터분석 Project </h3>
<h4 align='center'> (2023.05. ~ 2023.06.) </h4> 

![Aqua Lines](https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/aqua.png)

&nbsp;

## 1. 배경 및 목적

- 네이버 뉴스 본문 크롤링을 통한 특징 키워드 및 주제 분석
- 정치 및 법, 기술, 경제, 환경을 중심으로 한 주요 시사 별 Word Cloud를 통한 특징 키워드 추출 및 LDA를 통한 주제 분석

<br/>

## 2. 주최 기관

- 주최: AI빅데이터융합경영학과 전공 수업  ‘텍스트데이터분석’

<br/>

## 3. 프로젝트 기간 
- 2023.05 ~ 2023.06 (2개월)


<br/>

## 4. 프로젝트 설명 
<img width="530" alt="텍데분1" src="https://github.com/Ji-eun-Kim/Text-Data-Analytics/assets/124686375/8ecd0c22-ff86-476c-84d1-6b114c25c668"> | <img width="530" alt="텍데분2" src="https://github.com/Ji-eun-Kim/Text-Data-Analytics/assets/124686375/1e79b8af-1965-480c-843e-226631ba4f54"> 
---|---|

<img width="533" alt="텍데분3" src="https://github.com/Ji-eun-Kim/Text-Data-Analytics/assets/124686375/fa577161-e59f-4d56-b2f0-226cfe4b503b"> | <img width="533" alt="텍데분4" src="https://github.com/Ji-eun-Kim/Text-Data-Analytics/assets/124686375/a1c33180-9ff0-4ab5-8bb5-f23ddc32e228"> 
---|---|

본 프로젝트는 관심 있는 주제 5개 이상에 대해 텍스트 데이터를 수집하고, **최소 10,000개 이상의 데이터**를 확보해 진행한 프로젝트로, ‘주요 시사 별 Word Cloud를 통한 특징 키워드 추출 및 LDA를 통한 주제 분석’ 이라는 주제로 프로젝트를 진행하였다. 데이터 수집의 경우, **네이버 OpenAPI을 활용한 네이버 뉴스 본문을 크롤링**하였는데, 기사의 경우, 맞춤범 검증이 되었으며 대중적으로 많이 보는 뉴스 기사라고 판단하여 주요 시사인 대표 4가지 **정치 및 법, 기술, 경제, 환경**을 중심으로 **BeautifulSoup(bs4) 및 Selenium**을 활용하여 크롤링한 후, 중복값 제거를 통해 총 **10,400개의 데이터 수집**을 완료하였다. 

   전처리의 경우, 기존에 존재하는 기본적인 stopwords.txt를 활용해 **띄어쓰기와 영어 및 특수문자를 제거**해주었고, **Konlpy**를 통한 형태소 분석 또한 진행하였다. 이후, 2차적으로 불용어 처리를 한 번 더 하였는데, **value_counts()를** 찍어 필요하지 않은 조사들 (’도’, ‘이다’, ‘은’, ‘돼다’, ‘하고’)을 처리하였으며, 기사의 특성상 언급되는 불필요한 단어들 (’기자’, ‘제보’, ‘저자’, ‘방송’, ‘화면’, ‘캡처’, ‘리포트’, ‘영상편집’, ‘채널’, ‘구독’, ‘뉴스데스크’, ‘화면’, ‘현지’, ‘시각’, ‘연합뉴스’), 기자 이름(’앙카라’, ‘로이터’) 등을 추가적으로 **불용어 처리**하였다.
   
   시각화를 했을 때, 주요 키워드를 추출하는데 있어 가장 눈에 잘 보이는 라이브러리가 Word Cloud이었기에 **Word Cloud**를 사용해 주요 키워드 특징 분석을 진행하였다. 4개의 주제에 대한 **Word Cloud**를 진행한 결과, **정치 분야**에서는 **‘거부권 행사’, ‘간호’, ‘윤대통령’** 등으로 현 정부와 국회에서 이슈가 되는 안건이 많이 나왔으며, **기술 분야**에서는 **‘생성’, ‘개발’, ‘제공’** 과 같이 소프트웨어 업계에서 쓰이는 용어가 자주 등장하였다. 또한 **‘현재’, ‘올해’, ‘최근’, ‘새롭다’** 와 같은 시간 관련 용어가 많이 나오는 것을 통해 시간의 흐름에 민감한 것으로 나타났다. **경제 분야**의 경우, **‘투자 증권’, ‘미국’, ‘ 기업’** 등 경제 용어가 많이 등장하였으며, 시간의 흐름에 민감한 분야인 만큼 **‘최근’, ’지난’, ’올해’, ’현재’** 같은 키워드가 많이 도출되었다. **환경 분야**의 경우, ‘날씨’ 와 ‘재활용’을 주요 키워드로 선정하였으며 그에 따라 날씨와 관련된 경우, **‘낮’, ‘기온’, ‘최저’, ‘최고 기온’** 이 많이 등장하였고, 재활용과 관련된 경우, **‘폐 플라스틱’, ‘폐 배터리’, 자원 순환’** 이 주요 키워드로 등장하였다.

   LSA와 LDA 중 LDA가 LSA의 단점을 보완했다는 점, 그리고 시각화 부분에서도 보다 더 뛰어나다는 점에서 **LDA** 를 사용해 주제 분석을 진행하였다. 주요 topic은 4개였기에, **n_topics=4** 로 설정하여 4개 분야로 주제 분석이 잘 되었을지 확인해본 결과, 각 주제에 맞게 잘 분석이 되었음을 확인하였다. 또한 **n_topics** 를 더 높게 설정할수록 보다 세부적인 주제로 분석이 가능함을 시각화를 통해 확인할 수 있었다. 

   프로젝트를 진행한 후, **한계점 및 느낀점** 으로는 2가지 정도가 존재했다. 1. 양 대비 부족한 시간, 2. 크롤링의 다양성 이다. 시간의 여유가 더 있었더라면, 불용어 처리를 더 깔끔하게 할 수 있었을텐데 모델이 돌아가는데 약 6일이라는 시간이 걸려 많은 아쉬움이 남은 채 프로젝트를 마무리하였다. 크롤링의 다양성 같은 경우에는 네이버 뉴스 본문만 진행했지만, 유튜브 댓글이나 네티즌의 댓글도 크롤링하여 분석해보고 싶다는 아쉬움이 존재하였다.

<br/>

## 5. 팀원 및 담당 역할  

<팀원>  
- 개인 프로젝트  

<br>
  
<담당 역할>    
- 네이버 Open API를 활용한 약 10,400개의 네이버 뉴스 본문 크롤링(정치, 기술, 경제, 환경)
- Konlpy를 사용한 형태소 분석 및 불용어 처리
- Word Cloud를 활용한 각 시사 별 주요 키워드 특징 분석
- LDA를 활용한 주제 분석 (n_topics 파라미터 조절에 따른 결과 확인)

<br/>

## 6. 발표 자료 및 데이터

- 발표 자료  
https://drive.google.com/file/d/11RzQESiiQE40Ko6wUCFMtDZ2B0AX_ngI/view

- 데이터  
https://drive.google.com/drive/folders/1JhLosohVZVdgDfT44aNN3qAU3Vb48YIx?usp=drive_link

